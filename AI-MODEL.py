import streamlit as st
import requests, os, json, tempfile
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from st_audiorec import st_audiorec
from gtts import gTTS

# ------------------- Config -------------------
st.set_page_config(page_title="üåæ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï (‡§Ü‡§µ‡§æ‡•õ)", layout="wide")
st.title("üåæ AI ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§´‡§∏‡§≤ ‡§∏‡§≤‡§æ‡§π ‡§∏‡§π‡§æ‡§Ø‡§ï (‡§π‡§ø‡§Ç‡§¶‡•Ä, ‡§Ü‡§µ‡§æ‡•õ ‡§∏‡§π‡§ø‡§§)")

# ------------------- Load Env -------------------
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")
GROQ_BASE = "https://api.groq.com/openai/v1"
if not GROQ_API_KEY:
    st.error("‚ùå .env ‡§Æ‡•á‡§Ç GROQ_API_KEY ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç")
    st.stop()

# ------------------- Session State -------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if st.sidebar.button("‚ôªÔ∏è ‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç"):
    st.session_state.chat_history = []
    st.experimental_rerun()

# ------------------- Location, Soil & Weather -------------------
def get_user_location():
    try:
        res = requests.get("https://ipinfo.io/json", timeout=5)
        loc = res.json().get("loc", "28.61,77.20").split(",")
        return float(loc[0]), float(loc[1])
    except:
        return 28.61, 77.20

def fetch_soil(lat, lon):
    try:
        url = f"https://rest.isric.org/soilgrids/query?lon={lon}&lat={lat}&attributes=phh2o,nitrogen,ocd,sand,silt"
        r = requests.get(url, timeout=8)
        data = r.json().get("properties", {})
        return {k: v.get("M", {}).get("0-5cm", 0) for k,v in data.items()}
    except:
        return {"phh2o":6.5,"nitrogen":50,"ocd":10,"sand":40,"silt":40}

def fetch_weather(lat, lon):
    if not WEATHER_API_KEY: 
        return {"temp_c":25,"humidity":70,"precip_mm":2,"wind_kph":10}
    try:
        url = f"http://api.weatherapi.com/v1/current.json?key={WEATHER_API_KEY}&q={lat},{lon}"
        r = requests.get(url, timeout=8)
        c = r.json().get("current", {})
        return {"temp_c":c.get("temp_c",25),"humidity":c.get("humidity",70),"precip_mm":c.get("precip_mm",2),"wind_kph":c.get("wind_kph",10)}
    except:
        return {"temp_c":25,"humidity":70,"precip_mm":2,"wind_kph":10}

lat, lon = get_user_location()
soil_data = fetch_soil(lat, lon)
weather_data = fetch_weather(lat, lon)

st.sidebar.header("üìä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§î‡§∞ ‡§Æ‡•å‡§∏‡§Æ ‡§°‡•á‡§ü‡§æ")
st.sidebar.json({"‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä": soil_data, "‡§Æ‡•å‡§∏‡§Æ": weather_data})

# ------------------- ML Crop Model -------------------
def prepare_features(soil, weather):
    df = pd.DataFrame([soil])
    df = pd.concat([df, pd.DataFrame([weather])], axis=1).fillna(0)
    return StandardScaler().fit_transform(df)

X_scaled = prepare_features(soil_data, weather_data)

def train_model(X):
    np.random.seed(42)
    y = np.random.choice([0,1,2], size=X.shape[0])
    if X.shape[0]==1:
        X = np.tile(X,(20,1))
        y = np.random.choice([0,1,2], size=X.shape[0])
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X, y)
    return clf

clf = train_model(X_scaled)
crop_map = {0:"üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 1:"üå± ‡§ß‡§æ‡§®", 2:"üåΩ ‡§Æ‡§ï‡•ç‡§ï‡§æ"}
predicted_crop = crop_map.get(clf.predict(X_scaled)[0], "‚ùì ‡§Ö‡§ú‡•ç‡§û‡§æ‡§§")
st.sidebar.success(f"‚úÖ ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§∏‡•Å‡§ù‡§æ‡§µ: {predicted_crop}")

# ------------------- Groq LLM -------------------
MODEL_NAME = "gemma2-9b-it"
llm = ChatGroq(
    groq_api_key=GROQ_API_KEY,
    model_name=MODEL_NAME,
    temperature=0.7,
    streaming=True
)
template_text = """
‡§Ü‡§™ ‡§è‡§ï ‡§ó‡§æ‡§Å‡§µ ‡§ï‡§æ ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§î‡§∞ ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§® AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç‡•§  
‡§Ü‡§™‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§π‡•à ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•ã **hyper-localized, personalized ‡§î‡§∞ science-backed ‡§∏‡§≤‡§æ‡§π** ‡§¶‡•á‡§®‡§æ‡•§  
‡§Ü‡§™ friendly, ‡§∏‡§∞‡§≤ ‡§î‡§∞ ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Ä/‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§ú‡•à‡§∏‡•á ‡§ï‡•ã‡§à ‡§Ö‡§™‡§®‡•á ‡§ñ‡•á‡§§ ‡§Æ‡•á‡§Ç ‡§¨‡•à‡§†‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§∏‡•á ‡§¨‡§§‡§æ ‡§∞‡§π‡§æ ‡§π‡•ã‡•§  

‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø:  
1Ô∏è‚É£ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•á ‡§ñ‡•á‡§§ ‡§ï‡•Ä ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä, ‡§Æ‡•å‡§∏‡§Æ, ‡§î‡§∞ ‡§™‡§ø‡§õ‡§≤‡•á ‡§´‡§∏‡§≤ ‡§ö‡§ï‡•ç‡§∞ ‡§ï‡•á ‡§π‡§ø‡§∏‡§æ‡§¨ ‡§∏‡•á ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§Ç‡•§  
2Ô∏è‚É£ Soil Grids/Bhuvan satellite data, IoT sensors, weather forecast ‡§î‡§∞ crop rotation information ‡§ï‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§∞‡§ñ‡•á‡§Ç‡•§  
3Ô∏è‚É£ ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§ï‡•Ä ‡§Æ‡§æ‡§Ç‡§ó ‡§î‡§∞ ‡§≠‡§æ‡§µ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§â‡§ö‡§ø‡§§ ‡§´‡§∏‡§≤ ‡§î‡§∞ ‡§®‡§ø‡§µ‡•á‡§∂ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡•á‡§Ç‡•§  
4Ô∏è‚É£ yield, profit margin ‡§î‡§∞ sustainability score ‡§≠‡•Ä provide ‡§ï‡§∞‡•á‡§Ç‡•§  
5Ô∏è‚É£ ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§Ø‡§æ low-connectivity ‡§Æ‡•á‡§Ç ‡§≠‡•Ä ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡§æ advice system ‡§¨‡§®‡§æ‡§è‡§Ç‡•§  
6Ô∏è‚É£ Chat ‡§î‡§∞ voice interface ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§õ‡•ã‡§ü‡•á, ‡§∏‡§Æ‡§ù‡§®‡•á ‡§Ø‡•ã‡§ó‡•ç‡§Ø sentences ‡§¶‡•á‡§Ç‡•§  

‡§®‡§ø‡§Ø‡§Æ:  
1Ô∏è‚É£ ‡§Ö‡§ó‡§∞ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•ã‡§à ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§¨‡§§‡§æ‡§§‡§æ ‡§π‡•à (‡§ú‡•à‡§∏‡•á ‚Äú‡§Æ‡•á‡§∞‡•Ä ‡§Æ‡§ï‡•ç‡§ï‡§æ ‡§ñ‡§∞‡§æ‡§¨ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‚Äù), ‡§§‡•ã **‡§™‡§π‡§≤‡•á ‡§î‡§∞ details ‡§™‡•Ç‡§õ‡•á‡§Ç**:  
   - ‡§ñ‡•á‡§§ ‡§ï‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•à‡§∏‡•Ä ‡§π‡•à (dry, wet, nutrient status)?  
   - ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•à‡§∏‡§æ ‡§∞‡§π‡§æ? ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§π‡•Å‡§à ‡§ï‡•ç‡§Ø‡§æ?  
   - ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§ï‡§ø‡§§‡§®‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à?  
   - ‡§ï‡•Ä‡§ü-‡§Æ‡§ï‡•ã‡§°‡§º‡•á ‡§Ø‡§æ ‡§∞‡•ã‡§ó ‡§¶‡§ø‡§ñ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§ï‡•ç‡§Ø‡§æ?  
2Ô∏è‚É£ ‡§ï‡•á‡§µ‡§≤ ‡§§‡§¨ advice ‡§¶‡•á‡§Ç ‡§ú‡§¨ ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡§ø‡§≤ ‡§ú‡§æ‡§è‡•§  
3Ô∏è‚É£ ‡§π‡§∞ ‡§ú‡§µ‡§æ‡§¨ ‡§Æ‡•á‡§Ç **‡§ï‡§Æ ‡§∏‡•á ‡§ï‡§Æ 1 friendly tip, proverb ‡§Ø‡§æ ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ fact** ‡§ú‡§º‡§∞‡•Ç‡§∞ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§  
4Ô∏è‚É£ Soil/weather/farm advice ‡§Æ‡•á‡§Ç ‡§Ö‡§≤‡§ó crops, ‡§Æ‡•å‡§∏‡§Æ ‡§î‡§∞ ‡§ñ‡•á‡§§ ‡§ï‡§æ scenario ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§  
5Ô∏è‚É£ ‡§õ‡•ã‡§ü‡•á sentences, emojis ‡§î‡§∞ ‡§π‡§≤‡•ç‡§ï‡§æ ‡§Æ‡§ú‡§º‡§æ ‡§ú‡•ã‡§°‡§º‡•á‡§Ç‡•§  
6Ô∏è‚É£ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡§∞‡§≤ ‡§î‡§∞ encouraging tone ‡§∞‡§ñ‡•á‡§Ç‡•§  

‡§â‡§¶‡§æ‡§π‡§∞‡§£ interaction:  

User: "‡§Æ‡•á‡§∞‡•Ä ‡§Æ‡§ï‡•ç‡§ï‡§æ ‡§ñ‡§∞‡§æ‡§¨ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à"  
AI: "‡§Ö‡§∞‡•á ‡§≠‡§æ‡§à! ‡§•‡•ã‡§°‡§º‡§æ ‡§¨‡§§‡§æ‡§ì ‡§§‡•ã ‡§∏‡§π‡•Ä, ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•á ‡§ñ‡•á‡§§ ‡§Æ‡•á‡§Ç ‡§Æ‡§ï‡•ç‡§ï‡§æ ‡§ï‡§ø‡§∏ stage ‡§Æ‡•á‡§Ç ‡§π‡•à? üåΩ  
‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•à‡§∏‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§π‡•Å‡§à ‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç? Tip: '‡§ú‡•ã ‡§∏‡§Æ‡§Ø ‡§™‡§∞ ‡§ñ‡•á‡§§ ‡§ï‡§æ ‡§ú‡§æ‡§Ø‡§ú‡§æ ‡§≤‡•á‡§§‡§æ, ‡§µ‡§π‡•Ä ‡§®‡•Å‡§ï‡§∏‡§æ‡§® ‡§∏‡•á ‡§¨‡§ö‡§§‡§æ‡•§' üòÑ"

User (details ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§¶): "‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§•‡•ã‡§°‡§º‡•Ä ‡§∏‡•Ç‡§ñ‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§ï‡•Ä‡§ü ‡§≠‡•Ä ‡§¶‡§ø‡§ñ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç"  
AI: "‡§†‡•Ä‡§ï ‡§π‡•à ‡§≠‡§æ‡§à, ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§π‡§≤‡•ç‡§ï‡•Ä ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§ï‡§∞ ‡§¶‡•ã ‡§î‡§∞ ‡§ï‡•Ä‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡•Ä‡§Æ ‡§ï‡§æ ‡§∏‡•ç‡§™‡•ç‡§∞‡•á ‡§ï‡§∞ ‡§¶‡•ã‡•§ üåø  
Tip: '‡§¨‡•Ä‡§ú ‡§¨‡•ã‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§π‡•ã, ‡§§‡•ã ‡§ï‡§ü‡§æ‡§à ‡§ñ‡•Å‡§∂‡§π‡§æ‡§≤ ‡§π‡•ã‡§§‡•Ä‡•§' üòé  
Prediction: ‡§Ø‡§¶‡§ø ‡§Ø‡§π‡•Ä ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§ú‡§æ‡§∞‡•Ä ‡§∞‡§π‡•á ‡§§‡•ã ‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®‡§ø‡§§ yield 20 ‡§ï‡•ç‡§µ‡§ø‡§Ç‡§ü‡§≤/‡§π‡•á‡§ï‡•ç‡§ü‡•á‡§Ø‡§∞, profit margin ‡§≤‡§ó‡§≠‡§ó 15%, ‡§î‡§∞ soil sustainability score ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∞‡§π‡•á‡§ó‡§æ‡•§"
"""




prompt = ChatPromptTemplate.from_messages([
    ("system",template_text),
    ("user","{question}")
])
chain = prompt | llm | StrOutputParser()

# ------------------- Speech Functions -------------------
def speech_to_text(file_path): 
    url = f"{GROQ_BASE}/audio/transcriptions"
    with open(file_path,"rb") as f:
        resp = requests.post(
            url,
            headers={"Authorization":f"Bearer {GROQ_API_KEY}"},
            data={"model":"whisper-large-v3"},
            files={"file":(os.path.basename(file_path), f)},
            timeout=30
        )
    resp.raise_for_status()
    return resp.json().get("text","")

def text_to_speech(text, filename="response.mp3"):
    tts = gTTS(text, lang="hi")
    tts.save(filename)
    return filename

# ------------------- Chat Display -------------------
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Text input
if user_input := st.chat_input("‚úçÔ∏è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡•á‡§Ç..."):
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.chat_history.append({"role":"user","content":user_input})

    enriched = f"{user_input}\n\n‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä: {soil_data}\n‡§Æ‡•å‡§∏‡§Æ: {weather_data}\nML ‡§∏‡•Å‡§ù‡§æ‡§µ: {predicted_crop}\n‡§∏‡§∞‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"
    response_placeholder = st.empty()
    full_response = ""
    with st.spinner("ü§ñ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à..."):
        for chunk in chain.stream({"question": enriched}):
            full_response += chunk
            response_placeholder.markdown(full_response)

    st.session_state.chat_history.append({"role":"assistant","content": full_response})
    st.success("‚úÖ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞!")
    audio_file = text_to_speech(full_response)
    st.audio(audio_file, format="audio/mp3")

# ------------------- Voice Input -------------------
st.markdown("---")
st.subheader("üé§ ‡§¨‡•ã‡§≤‡§ï‡§∞ ‡§™‡•Ç‡§õ‡•á‡§Ç (Voice)")

col1, col2, col3 = st.columns([1,2,1])
with col2:
    wav_audio_data = st_audiorec()
    button_placeholder = st.empty()
    if wav_audio_data is not None:
        st.audio(wav_audio_data, format="audio/wav")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(wav_audio_data)
            audio_path = tmp.name

        # Show button immediately
        if button_placeholder.button("üîé ‡§ú‡§µ‡§æ‡§¨ ‡§™‡§æ‡§è‡§Ç"):
            with st.spinner("üîÑ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                voice_text = speech_to_text(audio_path)
                st.success(f"üó£ ‡§™‡§π‡§ö‡§æ‡§®‡§æ ‡§ó‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤: {voice_text}")

            enriched_voice = f"{voice_text}\n\n‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä: {soil_data}\n‡§Æ‡•å‡§∏‡§Æ: {weather_data}\nML ‡§∏‡•Å‡§ù‡§æ‡§µ: {predicted_crop}\n‡§∏‡§∞‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"
            response_placeholder_voice = st.empty()
            full_response_voice = ""
            with st.spinner("ü§ñ ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•à..."):
                for chunk in chain.stream({"question": enriched_voice}):
                    full_response_voice += chunk
                    response_placeholder_voice.markdown(full_response_voice)  # streaming without repetition

            st.session_state.chat_history.append({"role":"user","content": voice_text})
            st.session_state.chat_history.append({"role":"assistant","content": full_response_voice})

            reply_audio = text_to_speech(full_response_voice)
            st.success("‚úÖ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à ‚Äî ‡§®‡•Ä‡§ö‡•á ‡§∏‡•Å‡§®‡•á‡§Ç üëá")
            st.audio(reply_audio, format="audio/mp3")
