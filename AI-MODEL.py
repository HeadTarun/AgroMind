import streamlit as st
import requests, os, json, tempfile
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from st_audiorec import st_audiorec
from gtts import gTTS

# ------------------- Config -------------------
st.set_page_config(page_title="üåæ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï (‡§Ü‡§µ‡§æ‡•õ)", layout="wide")
st.title("üåæ AI ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§´‡§∏‡§≤ ‡§∏‡§≤‡§æ‡§π ‡§∏‡§π‡§æ‡§Ø‡§ï (‡§π‡§ø‡§Ç‡§¶‡•Ä, ‡§Ü‡§µ‡§æ‡•õ ‡§∏‡§π‡§ø‡§§)")

# ------------------- Load Env -------------------
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")
GROQ_BASE = "https://api.groq.com/openai/v1"
if not GROQ_API_KEY:
    st.error("‚ùå .env ‡§Æ‡•á‡§Ç GROQ_API_KEY ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç")
    st.stop()

# ------------------- Session State -------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if st.sidebar.button("‚ôªÔ∏è ‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç"):
    st.session_state.chat_history = []
    st.experimental_rerun()

# ------------------- Location, Soil & Weather -------------------
def get_user_location():
    try:
        res = requests.get("https://ipinfo.io/json", timeout=5)
        loc = res.json().get("loc", "28.61,77.20").split(",")
        return float(loc[0]), float(loc[1])
    except:
        return 28.61, 77.20

def fetch_soil(lat, lon):
    try:
        url = f"https://rest.isric.org/soilgrids/query?lon={lon}&lat={lat}&attributes=phh2o,nitrogen,ocd,sand,silt"
        r = requests.get(url, timeout=8)
        data = r.json().get("properties", {})
        return {k: v.get("M", {}).get("0-5cm", 0) for k,v in data.items()}
    except:
        return {"phh2o":6.5,"nitrogen":50,"ocd":10,"sand":40,"silt":40}

def fetch_weather(lat, lon):
    if not WEATHER_API_KEY: 
        return {"temp_c":25,"humidity":70,"precip_mm":2,"wind_kph":10}
    try:
        url = f"http://api.weatherapi.com/v1/current.json?key={WEATHER_API_KEY}&q={lat},{lon}"
        r = requests.get(url, timeout=8)
        c = r.json().get("current", {})
        return {"temp_c":c.get("temp_c",25),"humidity":c.get("humidity",70),"precip_mm":c.get("precip_mm",2),"wind_kph":c.get("wind_kph",10)}
    except:
        return {"temp_c":25,"humidity":70,"precip_mm":2,"wind_kph":10}

lat, lon = get_user_location()
soil_data = fetch_soil(lat, lon)
weather_data = fetch_weather(lat, lon)

st.sidebar.header("üìä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§î‡§∞ ‡§Æ‡•å‡§∏‡§Æ ‡§°‡•á‡§ü‡§æ")
st.sidebar.json({"‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä": soil_data, "‡§Æ‡•å‡§∏‡§Æ": weather_data})

# ------------------- ML Crop Model -------------------
def prepare_features(soil, weather):
    df = pd.DataFrame([soil])
    df = pd.concat([df, pd.DataFrame([weather])], axis=1).fillna(0)
    return StandardScaler().fit_transform(df)

X_scaled = prepare_features(soil_data, weather_data)

def train_model(X):
    np.random.seed(42)
    y = np.random.choice([0,1,2], size=X.shape[0])
    if X.shape[0]==1:
        X = np.tile(X,(20,1))
        y = np.random.choice([0,1,2], size=X.shape[0])
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X, y)
    return clf

clf = train_model(X_scaled)
crop_map = {0:"üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 1:"üå± ‡§ß‡§æ‡§®", 2:"üåΩ ‡§Æ‡§ï‡•ç‡§ï‡§æ"}
predicted_crop = crop_map.get(clf.predict(X_scaled)[0], "‚ùì ‡§Ö‡§ú‡•ç‡§û‡§æ‡§§")
st.sidebar.success(f"‚úÖ ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§∏‡•Å‡§ù‡§æ‡§µ: {predicted_crop}")

# ------------------- Groq LLM -------------------
MODEL_NAME = "gemma2-9b-it"
llm = ChatGroq(
    groq_api_key=GROQ_API_KEY,
    model_name=MODEL_NAME,
    temperature=0.7,
    streaming=True
)
template_text = """
‡§Ü‡§™ ‡§è‡§ï ‡§ó‡§æ‡§Å‡§µ ‡§ï‡§æ ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§î‡§∞ ‡§ï‡§ø‡§∏‡§æ‡§® AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç‡•§  
‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§∏‡•á **friendly, ‡§∏‡§∞‡§≤ ‡§î‡§∞ ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Ä** ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§ú‡•à‡§∏‡•á ‡§ï‡•ã‡§à ‡§Ö‡§™‡§®‡•á ‡§ñ‡•á‡§§ ‡§Æ‡•á‡§Ç ‡§¨‡•à‡§†‡•á ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§∏‡•á ‡§¨‡§§‡§æ ‡§∞‡§π‡§æ ‡§π‡•ã‡•§  

‡§®‡§ø‡§Ø‡§Æ:  
1. ‡§π‡§∞ ‡§∏‡§µ‡§æ‡§≤ ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ **‡§¶‡§Æ‡§¶‡§æ‡§∞ ‡§î‡§∞ ‡§Ö‡§≤‡§ó** ‡§π‡•ã, ‡§¨‡§æ‡§∞-‡§¨‡§æ‡§∞ ‡§µ‡§π‡•Ä ‡§® ‡§¶‡•ã‡§π‡§∞‡§æ‡§è‡§Å‡•§  
2. ‡§∏‡§ø‡§∞‡•ç‡§´ **‡§ï‡§ø‡§∏‡§æ‡§®‡•Ä ‡§î‡§∞ ‡§ñ‡•á‡§§‡•Ä ‡§∏‡•á ‡§ú‡•Å‡§°‡§º‡•á ‡§µ‡§ø‡§∑‡§Ø** ‡§™‡§∞ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç:  
   - ‡§´‡§∏‡§≤, ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä, ‡§Æ‡•å‡§∏‡§Æ, ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à, ‡§ï‡•Ä‡§ü-‡§Æ‡§ï‡•ã‡§°‡§º‡•á, ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ú‡•Ä‡§µ‡§®, ‡§ó‡§æ‡§Ç‡§µ ‡§ï‡•Ä ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß‡§ø‡§Ø‡§æ‡§Å  
   - general chat ‡§ú‡•à‡§∏‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≠‡•Ä, ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§ñ‡•á‡§§‡•Ä ‡§∏‡•á ‡§ú‡•Å‡§°‡§º‡§æ angle ‡§≤‡•á‡§Ç‡•§  
3. ‡§â‡§§‡•ç‡§§‡§∞ ‡§Æ‡•á‡§Ç **‡§π‡§∞ ‡§¨‡§æ‡§∞ ‡§ï‡§Æ ‡§∏‡•á ‡§ï‡§Æ 1 friendly tip, ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ fact ‡§Ø‡§æ ‡§ï‡§π‡§æ‡§µ‡§§** ‡§ú‡§º‡§∞‡•Ç‡§∞ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§  
4. Tone ‡§π‡§Æ‡•á‡§∂‡§æ **‡§∏‡§™‡•ã‡§∞‡•ç‡§ü‡§ø‡§µ, encouraging ‡§î‡§∞ ‡§ó‡§æ‡§Å‡§µ ‡§ú‡•à‡§∏‡§æ casual** ‡§π‡•ã‡•§  
5. Soil/weather/farm advice ‡§Æ‡•á‡§Ç ‡§π‡§∞ ‡§¨‡§æ‡§∞ **‡§Ö‡§≤‡§ó crops, ‡§Æ‡•å‡§∏‡§Æ ‡§î‡§∞ ‡§ñ‡•á‡§§ ‡§ï‡§æ scenario** ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•á‡§Ç‡•§  

‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§∏‡•ç‡§ü‡§æ‡§á‡§≤:  
User: "‡§Æ‡•á‡§∞‡§æ ‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡§æ ‡§ñ‡•á‡§§ ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§∏‡•Ç‡§ñ ‡§∞‡§π‡§æ ‡§π‡•à, ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡•á‡§Ç?"  
AI: "‡§Ö‡§∞‡•á ‡§≠‡§æ‡§à, ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§Æ‡§§ ‡§ï‡§∞! ‡§π‡§≤‡•ç‡§ï‡•Ä ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à ‡§ï‡§∞ ‡§¶‡•ã ‡§î‡§∞ ‡§∂‡§æ‡§Æ ‡§ï‡•ã ‡§ñ‡•á‡§§ ‡§Æ‡•á‡§Ç ‡§•‡•ã‡§°‡§º‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§¨‡§ø‡§õ‡§æ‡§à ‡§ï‡§∞ ‡§¶‡•ã, ‡§®‡§Æ‡•Ä ‡§¨‡§®‡•Ä ‡§∞‡§π‡•á‡§ó‡•Ä‡•§ üåæ  
Tip: ‡§ï‡§π‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à ‚Äì '‡§ú‡•ã ‡§ñ‡•á‡§§ ‡§Æ‡•á‡§Ç ‡§Æ‡•á‡§π‡§®‡§§ ‡§ï‡§∞‡§§‡§æ, ‡§µ‡§π‡•Ä ‡§∏‡•ã‡§®‡•á ‡§ï‡§æ ‡§´‡§≤ ‡§™‡§æ‡§§‡§æ‡•§' üòÑ"
"""


prompt = ChatPromptTemplate.from_messages([
    ("system",template_text),
    ("user","{question}")
])
chain = prompt | llm | StrOutputParser()

# ------------------- Speech Functions -------------------
def speech_to_text(file_path): 
    url = f"{GROQ_BASE}/audio/transcriptions"
    with open(file_path,"rb") as f:
        resp = requests.post(
            url,
            headers={"Authorization":f"Bearer {GROQ_API_KEY}"},
            data={"model":"whisper-large-v3"},
            files={"file":(os.path.basename(file_path), f)},
            timeout=30
        )
    resp.raise_for_status()
    return resp.json().get("text","")

def text_to_speech(text, filename="response.mp3"):
    tts = gTTS(text, lang="hi")
    tts.save(filename)
    return filename

# ------------------- Chat Display -------------------
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Text input
if user_input := st.chat_input("‚úçÔ∏è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡•á‡§Ç..."):
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.chat_history.append({"role":"user","content":user_input})

    enriched = f"{user_input}\n\n‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä: {soil_data}\n‡§Æ‡•å‡§∏‡§Æ: {weather_data}\nML ‡§∏‡•Å‡§ù‡§æ‡§µ: {predicted_crop}\n‡§∏‡§∞‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"
    response_placeholder = st.empty()
    full_response = ""
    with st.spinner("ü§ñ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à..."):
        for chunk in chain.stream({"question": enriched}):
            full_response += chunk
            response_placeholder.markdown(full_response)

    st.session_state.chat_history.append({"role":"assistant","content": full_response})
    st.success("‚úÖ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞!")
    audio_file = text_to_speech(full_response)
    st.audio(audio_file, format="audio/mp3")

# ------------------- Voice Input -------------------
st.markdown("---")
st.subheader("üé§ ‡§¨‡•ã‡§≤‡§ï‡§∞ ‡§™‡•Ç‡§õ‡•á‡§Ç (Voice)")

col1, col2, col3 = st.columns([1,2,1])
with col2:
    wav_audio_data = st_audiorec()
    button_placeholder = st.empty()
    if wav_audio_data is not None:
        st.audio(wav_audio_data, format="audio/wav")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(wav_audio_data)
            audio_path = tmp.name

        # Show button immediately
        if button_placeholder.button("üîé ‡§ú‡§µ‡§æ‡§¨ ‡§™‡§æ‡§è‡§Ç"):
            with st.spinner("üîÑ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                voice_text = speech_to_text(audio_path)
                st.success(f"üó£ ‡§™‡§π‡§ö‡§æ‡§®‡§æ ‡§ó‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤: {voice_text}")

            enriched_voice = f"{voice_text}\n\n‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä: {soil_data}\n‡§Æ‡•å‡§∏‡§Æ: {weather_data}\nML ‡§∏‡•Å‡§ù‡§æ‡§µ: {predicted_crop}\n‡§∏‡§∞‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§è‡§Ç‡•§"
            response_placeholder_voice = st.empty()
            full_response_voice = ""
            with st.spinner("ü§ñ ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•à..."):
                for chunk in chain.stream({"question": enriched_voice}):
                    full_response_voice += chunk
                    response_placeholder_voice.markdown(full_response_voice)  # streaming without repetition

            st.session_state.chat_history.append({"role":"user","content": voice_text})
            st.session_state.chat_history.append({"role":"assistant","content": full_response_voice})

            reply_audio = text_to_speech(full_response_voice)
            st.success("‚úÖ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à ‚Äî ‡§®‡•Ä‡§ö‡•á ‡§∏‡•Å‡§®‡•á‡§Ç üëá")
            st.audio(reply_audio, format="audio/mp3")
