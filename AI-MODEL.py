import streamlit as st
import requests, os, json, tempfile, time, random
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from st_audiorec import st_audiorec
from gtts import gTTS

# ------------------- Config -------------------
st.set_page_config(page_title="üåæ AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§π‡§æ‡§Ø‡§ï", layout="wide")

# ------------------- Welcome Screen -------------------
welcome_messages = [
    "üå± ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à! ‡§ê‡§™ ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à‚Ä¶ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§•‡•ã‡§°‡§º‡•Ä ‡§¶‡•á‡§∞ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç‚Ä¶",
    "üåø ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡§ø‡§∏‡§æ‡§® ‡§≠‡§æ‡§à! ‡§Ü‡§™‡§ï‡§æ AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à‚Ä¶ ‡§ß‡•à‡§∞‡•ç‡§Ø ‡§∞‡§ñ‡•á‡§Ç‚Ä¶",
    "üåæ ‡§π‡§≤‡§ö‡§≤ ‡§Æ‡§ö ‡§∞‡§π‡•Ä ‡§π‡•à! ‡§ê‡§™ ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§π‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§ó‡§æ‚Ä¶",
    "üåª ‡§ñ‡•á‡§§ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‚Ä¶ ‡§ï‡•Å‡§õ ‡§π‡•Ä ‡§™‡§≤‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§∂‡•Å‡§∞‡•Ç!",
    "üçÉ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à! AI ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§Ü‡§™‡§ï‡•á ‡§ñ‡•á‡§§ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à‚Ä¶"
]
with st.spinner(random.choice(welcome_messages)):
    time.sleep(5)

st.title("üåæ AI ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§´‡§∏‡§≤ ‡§∏‡§≤‡§æ‡§π ‡§∏‡§π‡§æ‡§Ø‡§ï (‡§π‡§ø‡§Ç‡§¶‡•Ä, ‡§Ü‡§µ‡§æ‡•õ ‡§∏‡§π‡§ø‡§§)")

# ------------------- Load Env -------------------
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")
GROQ_BASE = "https://api.groq.com/openai/v1"

if not GROQ_API_KEY:
    st.error("‚ùå .env ‡§Æ‡•á‡§Ç GROQ_API_KEY ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç")
    st.stop()

# ------------------- Session State -------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if st.sidebar.button("‚ôªÔ∏è ‡§ö‡•à‡§ü ‡§∞‡•Ä‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç"):
    st.session_state.chat_history = []
    st.experimental_rerun()

# ------------------- Location, Soil & Weather -------------------
@st.cache_data(ttl=3600)
def get_user_location():
    try:
        res = requests.get("https://ipinfo.io/json", timeout=3)
        loc = res.json().get("loc", "28.61,77.20").split(",")
        return float(loc[0]), float(loc[1])
    except:
        return 28.61, 77.20

@st.cache_data(ttl=3600)
def fetch_soil(lat, lon):
    try:
        url = f"https://rest.isric.org/soilgrids/query?lon={lon}&lat={lat}&attributes=phh2o,nitrogen,ocd,sand,silt"
        r = requests.get(url, timeout=4)
        data = r.json().get("properties", {})
        return {k: v.get("M", {}).get("0-5cm", 0) for k,v in data.items()}
    except:
        return {"phh2o":6.5,"nitrogen":50,"ocd":10,"sand":40,"silt":40}

@st.cache_data(ttl=600)
def fetch_weather(lat, lon):
    if not WEATHER_API_KEY:
        return {"temp_c":25,"humidity":70,"precip_mm":2,"wind_kph":10}
    try:
        url = f"http://api.weatherapi.com/v1/current.json?key={WEATHER_API_KEY}&q={lat},{lon}"
        r = requests.get(url, timeout=4)
        c = r.json().get("current", {})
        return {"temp_c":c.get("temp_c",25),"humidity":c.get("humidity",70),
                "precip_mm":c.get("precip_mm",2),"wind_kph":c.get("wind_kph",10)}
    except:
        return {"temp_c":25,"humidity":70,"precip_mm":2,"wind_kph":10}

lat, lon = get_user_location()
soil_data = fetch_soil(lat, lon)
weather_data = fetch_weather(lat, lon)

st.sidebar.header("üìä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§î‡§∞ ‡§Æ‡•å‡§∏‡§Æ ‡§°‡•á‡§ü‡§æ")
st.sidebar.json({"‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä": soil_data, "‡§Æ‡•å‡§∏‡§Æ": weather_data})

# ------------------- ML Crop Model -------------------
@st.cache_resource
def get_trained_model(X_scaled):
    np.random.seed(42)
    y = np.random.choice([0,1,2], size=X_scaled.shape[0])
    if X_scaled.shape[0]==1:
        X_scaled = np.tile(X_scaled,(20,1))
        y = np.random.choice([0,1,2], size=X_scaled.shape[0])
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_scaled, y)
    return clf

def prepare_features(soil, weather):
    df = pd.DataFrame([soil])
    df = pd.concat([df, pd.DataFrame([weather])], axis=1).fillna(0)
    return StandardScaler().fit_transform(df)

X_scaled = prepare_features(soil_data, weather_data)
clf = get_trained_model(X_scaled)
crop_map = {0:"üåæ ‡§ó‡•á‡§π‡•Ç‡§Å", 1:"üå± ‡§ß‡§æ‡§®", 2:"üåΩ ‡§Æ‡§ï‡•ç‡§ï‡§æ"}
predicted_crop = crop_map.get(clf.predict(X_scaled)[0], "‚ùì ‡§Ö‡§ú‡•ç‡§û‡§æ‡§§")
st.sidebar.success(f"‚úÖ ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§∏‡•Å‡§ù‡§æ‡§µ: {predicted_crop}")

# ------------------- Groq LLM -------------------
MODEL_NAME = "openai/gpt-oss-20B"
llm = ChatGroq(
    groq_api_key=GROQ_API_KEY,
    model_name=MODEL_NAME,
    temperature=0.7,
    streaming=True
)

template_text = """‡§Ü‡§™ ‡§è‡§ï ‡§ó‡§æ‡§Å‡§µ ‡§ï‡§æ ‡§¶‡•ã‡§∏‡•ç‡§§ ‡§î‡§∞ ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§® AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç‡•§  
‡§Ü‡§™ friendly, ‡§∏‡§∞‡§≤ ‡§î‡§∞ ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Ä/‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§ï‡•á‡§µ‡§≤ ‡§ñ‡•á‡§§‡•Ä ‡§î‡§∞ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§∏‡•á ‡§ú‡•Å‡§°‡§º‡•Ä ‡§¨‡§æ‡§§‡•á‡§Ç ‡§ï‡§∞‡•á‡§Ç‡•§  
ML ‡§´‡§∏‡§≤ prediction ‡§ï‡•á‡§µ‡§≤ ‡§§‡§¨ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç ‡§ú‡§¨ user ‡§™‡•Ç‡§õ‡•á "‡§ï‡•å‡§® ‡§∏‡•Ä ‡§´‡§∏‡§≤ ‡§â‡§ó‡§æ‡§ä‡§Å" ‡§Ø‡§æ "‡§´‡§∏‡§≤ ‡§∏‡•Å‡§ù‡§æ‡§µ".  
Soil ‡§î‡§∞ Weather ‡§ï‡•á ‡§∏‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§™‡§∞ raw API ‡§°‡•á‡§ü‡§æ ‡§ï‡§æ farmer-friendly explanation ‡§¶‡•á‡§Ç‡•§  
Market ‡§î‡§∞ real-time info ‡§™‡•Ç‡§õ‡•á ‡§§‡•ã ‡§ï‡§π‡•á‡§Ç: "‡§Ø‡§π ‡§´‡•Ä‡§ö‡§∞ ‡§Ö‡§≠‡•Ä ‡§°‡•á‡§µ‡§≤‡§™‡§Æ‡•á‡§Ç‡§ü ‡§Æ‡•á‡§Ç ‡§π‡•à‡•§ AgroMind ‡§ü‡•Ä‡§Æ ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä ‡§á‡§∏‡•á ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ï‡§∞‡§æ‡§è‡§ó‡•Ä‡•§"
"""

prompt = ChatPromptTemplate.from_messages([
    ("system", template_text),
    ("user", "{question}")
])
chain = prompt | llm | StrOutputParser()

# ------------------- Speech Functions -------------------
def speech_to_text(file_path):
    url = f"{GROQ_BASE}/audio/transcriptions"
    with open(file_path,"rb") as f:
        resp = requests.post(
            url,
            headers={"Authorization":f"Bearer {GROQ_API_KEY}"},
            data={"model":"whisper-large-v3"},
            files={"file":(os.path.basename(file_path), f)},
            timeout=30
        )
    resp.raise_for_status()
    return resp.json().get("text","")

def text_to_speech(text, filename="response.mp3"):
    tts = gTTS(text, lang="hi")
    tts.save(filename)
    return filename

# ------------------- Input Enrichment -------------------
def enrich_input(user_text):
    user_lower = user_text.lower()
    context_text = user_text

    if "‡§´‡§∏‡§≤" in user_lower or "crop" in user_lower:
        context_text += f"\n‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä: {soil_data}\n‡§Æ‡•å‡§∏‡§Æ: {weather_data}\nML ‡§∏‡•Å‡§ù‡§æ‡§µ: {predicted_crop}"

    elif any(word in user_lower for word in ["‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä", "soil", "weather", "‡§Æ‡•å‡§∏‡§Æ", "pH", "‡§®‡§æ‡§á‡§ü‡•ç‡§∞‡•ã‡§ú‡§®", "nitrogen"]):
        context_text += f"\n‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§î‡§∞ ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä:\n{soil_data}\n{weather_data}\n‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡§∞‡§≤ ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ ‡§¶‡•á‡§Ç‡•§"

    elif any(word in user_lower for word in ["‡§¨‡§æ‡§ú‡§æ‡§∞", "market", "‡§≠‡§æ‡§µ", "price"]):
        context_text = "‡§Ø‡§π ‡§´‡•Ä‡§ö‡§∞ ‡§Ö‡§≠‡•Ä ‡§°‡•á‡§µ‡§≤‡§™‡§Æ‡•á‡§Ç‡§ü ‡§Æ‡•á‡§Ç ‡§π‡•à‡•§ AgroMind ‡§ü‡•Ä‡§Æ ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä ‡§á‡§∏‡•á ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§ï‡§∞‡§æ‡§è‡§ó‡•Ä‡•§"

    return context_text

# ------------------- Voice Input -------------------
st.subheader("üé§ ‡§¨‡•ã‡§≤‡§ï‡§∞ ‡§™‡•Ç‡§õ‡•á‡§Ç (Voice Input)")
col1, col2, col3 = st.columns([1,2,1])
with col2:
    wav_audio_data = st_audiorec()
    button_placeholder = st.empty()
    if wav_audio_data is not None:
        st.audio(wav_audio_data, format="audio/wav")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(wav_audio_data)
            audio_path = tmp.name

        if button_placeholder.button("üîé ‡§ú‡§µ‡§æ‡§¨ ‡§™‡§æ‡§è‡§Ç"):
            with st.spinner("üîÑ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                voice_text = speech_to_text(audio_path)
                st.success(f"üó£ ‡§™‡§π‡§ö‡§æ‡§®‡§æ ‡§ó‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤: {voice_text}")

            enriched_voice = enrich_input(voice_text)
            response_placeholder_voice = st.empty()
            full_response_voice = ""
            with st.spinner("ü§ñ ‡§ú‡§µ‡§æ‡§¨ ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•à..."):
                for chunk in chain.stream({"question": enriched_voice}):
                    full_response_voice += chunk
                    response_placeholder_voice.markdown(full_response_voice)

            st.session_state.chat_history.append({"role":"user","content": voice_text})
            st.session_state.chat_history.append({"role":"assistant","content": full_response_voice})

            st.markdown("### üéß ‡§Ü‡§µ‡§æ‡•õ ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ (Voice Response)")
            reply_audio = text_to_speech(full_response_voice)
            st.audio(reply_audio, format="audio/mp3")

# ------------------- Chat Display -------------------
st.subheader("üí¨ ‡§ö‡•à‡§ü ‡§Æ‡•á‡§Ç ‡§∏‡§µ‡§æ‡§≤-‡§ú‡§µ‡§æ‡§¨")
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ------------------- Text Input -------------------
if user_input := st.chat_input("‚úçÔ∏è ‡§Ö‡§™‡§®‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡•á‡§Ç..."):
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.chat_history.append({"role":"user","content":user_input})

    enriched = enrich_input(user_input)
    response_placeholder = st.empty()
    response_placeholder.markdown("ü§ñ AI ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•à‚Ä¶ üß†")
    full_response = ""
    with st.spinner("ü§ñ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à..."):
        for chunk in chain.stream({"question": enriched}):
            full_response += chunk
            response_placeholder.markdown(full_response)

    st.session_state.chat_history.append({"role":"assistant","content": full_response})
    st.markdown("### üéß ‡§Ü‡§µ‡§æ‡•õ ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ (Voice Response)")
    audio_file = text_to_speech(full_response)
    st.audio(audio_file, format="audio/mp3")
